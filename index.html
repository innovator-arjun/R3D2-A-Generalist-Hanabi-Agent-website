<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=" First MARL agent that can play different Hanabi settings and cooperate with other algorithmic agents">
  <meta name="keywords" content="Multi-Agent Reinforcement Learning (MARL), Cooperative game, Multi Agent Text-based game">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>R3D2: A Generalist Hanabi Agent  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">A Generalist Hanabi Agent</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.arjunvaithilingamsudhakar.com/">Arjun Vaithilingam Sudhakar</a><sup>* 1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://hnekoeiq.github.io/">Hadi Nekoei</a><sup>* 1,2,4</sup>,</span>
            <span class="author-block">
              <a href="https://mathieu-reymond.github.io/">Mathieu Reymond</a><sup>1,2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/umich.edu/janarthanan-rajendran/">Janarthanan Rajendran</a><sup>6</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/miaoliuhome">Miao Liu</a><sup>5</sup>,
            </span>
            <span class="author-block">
              <a href="https://sarathchandar.in/">Sarath Chandar</a><sup>1,2,3,7</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Chandar Research Lab</span>
            <span class="author-block"><sup>2</sup>Mila-Quebec AI Institute</span>
            <span class="author-block"><sup>3</sup>Polytechnique Montreal</span>
            <span class="author-block"><sup>4</sup>Universite de Montreal</span>
            <span class="author-block"><sup>5</sup>IBM Research</span>
            <span class="author-block"><sup>6</sup>Dalhousie University</span>
            <span class="author-block"><sup>7</sup>Canada CIFAR AI Chair</span>

          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/pdf?id=pCj2sLNoJq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://openreview.net/forum?id=pCj2sLNoJq"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/@chandar-lab9459"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/chandar-lab/R3D2-A-Generalist-Hanabi-Agent/tree/dev_r3d2"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Checkpoints</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="item item-fullbody">
        <figure class="image">
          <img src="./static/images/r3d2_archi.jpg" alt="Fullbody Preview">
        </figure>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            <p><strong>Traditional Multi-Agent Reinforcement Learning (MARL) Limitations:</strong></p>  
            <p>MARL systems develop cooperative strategies through repeated interactions. However, they struggle to generalize beyond their training setting and fail to collaborate effectively with unfamiliar agents.</p>  

            <p><strong>The Hanabi Benchmark Challenge:</strong></p>  
            <p>Hanabi, a popular 2-to-5 player cooperative card game, requires complex reasoning and precise assistance. Current MARL agents can only play in fixed game settings (e.g., 2-player) and with the same algorithmic agents, unlike humans who adapt dynamically to new partners.</p>  

            <p><strong>Introducing R3D2:</strong></p>  
            <ul>  
              <li><strong>Recurrent Replay Relevance Distributed DQN (R3D2)</strong> is a generalist agent designed to overcome these limitations.</li>  
              <li>We reformulate Hanabi using text-based inputs, leveraging language for improved transfer learning.</li>  
              <li>R3D2 employs a distributed MARL algorithm to handle dynamic observation- and action-spaces.</li>  
              <li>It is the first agent capable of playing all Hanabi game settings concurrently and extending strategies across different settings.</li>  
              <li>Unlike previous agents, R3D2 can collaborate with various algorithmic agents that otherwise fail to do so.</li>  
            </ul>  

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">


    <!--/ Matting. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">

        <div class="content">
          <h2 class="title is-3">Hanabi Template - Text</h2>
          <p><strong>Our first contribution:</strong> We frame Hanabi as a text-based game, inspired by the success of language models like GPT in transfer learning.</p>  

<p>This textual representation includes all necessary game information: <u>Life and clue tokens, Visible hands, Discarded cards, Hints </u></p> 

            <figure class="image">
              <img src="./static/images/hanabi_archi.jpg" alt="Fullbody Preview" style="width: 40%; height: auto;">
            </figure>


        </div>
        <!-- Interpolating. -->
        <h3 class="title is-4">Policy Transfer - Zeroshot setting:</h3>
        <div class="content has-text-justified">
          <p><strong>Background:</strong></p>  
          <p>In multi-agent Hanabi, increasing the number of players introduces greater complexity, making strategy coordination more difficult.  
          A well-designed agent should not only adapt across different game settings but also transfer knowledge effectively between them.</p>  

          <p><strong>Key Observations:</strong></p>  
          <ul>  
            <li>As the number of players increases, overall performance decreases due to increased strategy complexity.</li>  
            <li>R3D2-M learns competitive strategies across settings and effectively transfers knowledge, unlike R2D2-text.</li>  
            <li>Despite training via self-play, R3D2 maintains high cross-play performance, adapting well to new partners.</li>  
            <li>Dynamic action-space handling is crucial for learning generalizable policies, beyond just textual observations.</li>  
          </ul>

          
        </div>
        <figure class="image">
          <img src="./static/images/results.png" alt="Fullbody Preview">
        </figure>

        <br/>
        <!--/ Interpolating. -->
        <h3 class="title is-4">Zero-shot coordination matrix:</h3>
        <!-- Results. -->
        <div class="content has-text-justified">
        <p><strong>R3D2's Robustness in Cross-Play:</strong></p>
        <p>We compared R3D2’s policies in cross-play settings with other baseline algorithms, evaluating performance across multiple seeds. The results highlight R3D2's robustness, especially in inter-XP, where it outperforms R2D2 and R2D2-OP. This suggests R3D2 learns more general strategies, making it more adaptable to new agents and game settings.</p>

        <p><strong>Key Observations:</strong></p>
        <ul>
          <li>R2D2 and R2D2-OP showed lower intra-XP performance compared to self-play, especially surprising for R2D2-OP, which is designed for better cooperation.</li>
          <li>R3D2's performance in intra-XP was on par with self-play, proving that self-play can lead to robust strategies when using the right representation.</li>
          <li>R3D2 consistently outperforms in inter-XP, especially when paired with R2D2-OBL, indicating its ability to learn transferable strategies across diverse agents.</li>
          <li>R3D2-M, trained on multiple settings, demonstrated better adaptability in inter-XP, benefiting from exposure to diverse strategies during training.</li>
        </ul>

        <p><strong>Key Takeaway:</strong></p>
        <p>R3D2's ability to adapt to new agents and game settings makes it a powerful tool for multi-agent cooperation. Its robustness in cross-play scenarios shows that self-play, when paired with the right representations, can produce more flexible and transferable strategies than methods designed for zero-shot cooperation.</p>
        </div>


        <!--/ Results. -->

        <div class="item item-fullbody" style="display: flex; gap: 20px;"> 
          <figure class="image is-3by2" style="flex: 0.5;"> 
            <img src="/static/images/sp_cp_barplot.jpg" alt="Bar Plot" style="width: 100%; height: 55%; "> 
          </figure> 
          <figure class="image is-3by2" style="flex: 0.7;"> 
            <img src="/static/images/cp_matrix.jpg" alt="Matrix" style="width: 100%; height: 70%;"> 
          </figure> 
        </div>


          <h2 class="title is-3">Video</h2>
          <div class="publication-video">

          <iframe src="https://www.youtube.com/embed/2PUEib21nFc?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

          </div>


        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      sudhakar2025a,
      title={A Generalist Hanabi Agent},
      author={Arjun V Sudhakar and Hadi Nekoei and Mathieu Reymond and Miao Liu and Janarthanan Rajendran and Sarath Chandar},
      booktitle={The Thirteenth International Conference on Learning Representations},
      year={2025},
      url={https://openreview.net/forum?id=pCj2sLNoJq}
      }</code></pre>
  </div>
</section>

<!-- 
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer> -->

</body>
</html>
